I am a Software Service and IP provider. My goal is to deliver AI products to SMB. My first customer is a politician. Build a chatbot with the following specs:

Users will submit queries and should get responses. For now, the UI should be lightweight, almost as simple as texting.
The structure should be a RAG server, but it needs some special features, like logging (probably requiring an opt-in approval) every query and response.
I want python code with an API interface. It's a chatbot that answers queries based on content in a RAG.
Don't use OpenAI or any paid service. Do everything with open-source models and vectorizers for now. There are 3 deliveries - 1 for a developer and 2 executables (PyInstaller):
Internal where I build the environment and run on a Debian12 laptop
External where my customer has clear instructions to install an executable without all the complexities of installing python, but it just runs. He uses a Mac.
Internal where I test the executable and instructions for my customer. This will be a Windows11 machine.
Use weaviate. They gave me some advice, but I think FastAPI will be better than FAISS- ''' You're on the right track - Elysia is probably overkill for your use case. Your Flask + .generate.near_text() setup is the fastest path to production.
Before I give you specific recommendations, I need to understand three things:

Volume - How many texts per day? Timeline - When do you need this live? Accuracy - Is a wrong answer just annoying, or does it create compliance risk? Your answers will determine whether you need optimizations or can ship as-is.

Here's what matters based on your situation:

If you're doing high volume (1000+ msgs/day), make sure you're reusing the same Weaviate client across requests instead of creating a new one per text. The instantiation overhead will slow you down.

If accuracy is critical;

Bump your limit from 2 to 5-10 results so the LLM has more context Add Autocut to filter out irrelevant stuff that causes hallucinations If problems persist, we can discuss reranking (adds a second step but improves accuracy) May be worht updating your prompt to avoid SMS encoding issues:

##. grouped_task="Answer in "X" sentence. Plain text only - no quotes or special characters." This keeps you under 160 characters and prevents the message from switching to Unicode encoding (which cuts your limit to 70 chars and doubles your cost). ''' We will eventually need to pare the results to SMS formats, but, for now, let's just get all the chatting working satisfactorily with content. Answers to Weaviate's questions: 1k+, Monday for testing, Wrong answers are a serious problem (thus the need to identify low confidence answers and offer to call back instead). I think PyInstaller is best so that everything is self-contained in the file. I think the best organization of collections is:

BrandonPlatform. These are his own statements/speeches, so we are taking the words straight from the horse's mouth. His synthesis of the RNC and Independent platforms would go in here. These share the highest confidence scores with Previous Q&A.
Previous Q&A. This shares the highest confidence scores.
PartyPlatform. These are the RNC and Independent platforms, for example. They are the lowest confidence score in Collections and are mostly for comparison purposes to what he believes. I need to add an Arizona-specific Republican platform, as I am sure there are local issues, like water rights, that are important but not mentioned in the national one.
Internet (not really a collection). These are the lowest confidence scores. Everything from the internet must be accompanied with a citation.
Critically, the chatbot must recognize if it doesn't know or isn't sure about an answer and offer to collect contact information to be called back personally, Record every new question received, or, preferably, record every interaction so that things can be refined with time and more data. If the user declines to opt-in, I still want to record new questions not currently in the Previous Q&A to the extent it is morally and ethically sound to do so. To simplify some of the process, I suggest using containers to avoid PyInstaller and complexity issues? That should let us use Weaviate and Ollama via Docker containers.