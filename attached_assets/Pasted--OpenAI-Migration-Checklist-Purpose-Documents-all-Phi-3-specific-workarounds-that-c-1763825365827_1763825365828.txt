---

## OpenAI Migration Checklist

**Purpose**: Documents all Phi-3-specific workarounds that can be removed when migrating to OpenAI's API (10-30x faster respo
nses, streaming support, better quality at ~$0.01-0.05 per query).

### Files to Remove (saves ~2.5GB)
- [ ] `download_phi3_model.py` - Model download script
- [ ] `phi3_model/` directory - 2GB ONNX model files
- [ ] `backend/phi3_client.py` - Replace with ~50 line OpenAI client

### Dependencies to Update
- [ ] Remove from requirements.txt: `onnxruntime`, `tiktoken`
- [ ] Add to requirements.txt: `openai`
- [ ] Optional: Keep `sentence-transformers` (zero cost) or switch to OpenAI embeddings

### Code Changes Required

**backend/phi3_client.py** - REPLACE ENTIRELY:
```python
# New openai_client.py (~50 lines)
from openai import OpenAI
class OpenAIClient:
    def __init__(self):
        self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        self.model = "gpt-4o-mini"
    async def generate_response(self, user_query, system_prompt, confidence):
        response = await self.client.chat.completions.create(
            model=self.model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_query}
            ],
            max_tokens=2048,
            temperature=0.7,
            stream=True
        )
```

**backend/rag_pipeline.py**:
- [ ] Remove Phi-3 chat template (`<|system|>...<|end|>` formatting)
- [ ] Expand compressed prompts (~350 chars → ~800 chars with 128k context)
- [ ] Remove token budget constraints (tiktoken encoding/counting)
- [ ] Simplify `_build_multi_section_prompt()` to return OpenAI messages

**backend/main.py**:
- [ ] Remove lazy loading system (5-min idle timeout, model unload/reload)
- [ ] Replace `Phi3Client()` with `OpenAIClient()`
- [ ] Remove model loading logic (instant startup)

### Configuration
- [ ] Add to Replit Secrets: `OPENAI_API_KEY`
- [ ] Optional: `OPENAI_MODEL=gpt-4o-mini` (default) or `gpt-4o` (premium)

### Migration Steps (90 minutes total)
1. [ ] Get OpenAI API key, add to Replit Secrets (10 min)
2. [ ] Create `openai_client.py`, update imports (30 min)
3. [ ] Remove Phi-3 formatting, expand prompts (30 min)
4. [ ] Test all scenarios: policy, comparison, debate, low-confidence (15 min)
5. [ ] Delete Phi-3 files, clean up dependencies (10 min)

### Expected Improvements
- **Speed**: 30-60 sec → 2-5 sec per response (10-30x faster)
- **Quality**: Better reasoning, fewer hallucinations
- **UX**: Streaming responses, instant startup
- **Resources**: 4GB RAM → 1GB RAM (no local model)
- **Cost**: $0 → ~$0.01-0.05 per query (ROI: massive UX improvement)

### Rollback Plan
Keep `phi3_client.py` in git history. To rollback: revert changes, re-run `python download_phi3_model.py`.